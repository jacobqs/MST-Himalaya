{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81b5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is part of Shyft. Copyright 2015-2018 SiH, JFB, OS, YAS, Statkraft AS\n",
    "# See file COPYING for more details **/\n",
    "from os import path\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "#from shyft.hydrology import shyftdata_dir\n",
    "from shyft.time_series import (TimeAxis, UtcTimeVector)\n",
    "from shyft.hydrology.repository import interfaces\n",
    "from shyft.hydrology.repository.netcdf.time_conversion import convert_netcdf_time\n",
    "from shyft.hydrology.repository.netcdf.utils import _limit_1D, _numpy_to_geo_ts_vec, _make_time_slice, _slice_var_1D\n",
    "\n",
    "\n",
    "class CFDataRepositoryError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CFDataRepost(interfaces.GeoTsRepository):\n",
    "    \"\"\"\n",
    "    Repository for geo located timeseries stored in netCDF files.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsg, filename, padding=5000.):\n",
    "        filename = path.expandvars(filename)\n",
    "\n",
    "        if not path.isabs(filename):\n",
    "            # Relative paths will be prepended the data_dir\n",
    "            filename = path.join(shyftdata_dir, filename)\n",
    "        if not path.isfile(filename):\n",
    "            raise CFDataRepositoryError(\"No such file '{}'\".format(filename))\n",
    "\n",
    "        self._filename = filename\n",
    "        self.allow_subset = True  # allow_subset\n",
    "\n",
    "        self.shyft_cs = f\"+init=EPSG:{epsg}\"\n",
    "        self._padding = padding\n",
    "\n",
    "        # Field names and mappings netcdf_name: shyft_name\n",
    "        self._nc_shyft_map = {\"relative_humidity\": \"relative_humidity\",\n",
    "                              \"temperature\": \"temperature\",\n",
    "                              \"z\": \"z\",\n",
    "                              \"precipitation\": \"precipitation\",\n",
    "                              \"precipitation_amount_acc\": \"precipitation\",\n",
    "                              \"wind_speed\": \"wind_speed\",\n",
    "                              \"global_radiation\": \"radiation\",\n",
    "                              \"discharge\": \"discharge\"}\n",
    "\n",
    "        self._shift_fields = (\"precipitation_amount_acc\",\n",
    "                              \"integral_of_surface_downwelling_shortwave_flux_in_air_wrt_time\")\n",
    "\n",
    "    def get_timeseries(self, input_source_types, utc_period, geo_location_criteria=None):\n",
    "        \"\"\"\n",
    "        see interfaces.GeoTsRepository\n",
    "        \"\"\"\n",
    "\n",
    "        with Dataset(self._filename) as dataset:\n",
    "            return self._get_data_from_dataset(dataset, input_source_types,\n",
    "                                               utc_period, geo_location_criteria)\n",
    "\n",
    "    def _get_data_from_dataset(self, dataset, input_source_types, utc_period,\n",
    "                               geo_location_criteria):\n",
    "\n",
    "        x = dataset.variables.get(\"x\", None)\n",
    "        y = dataset.variables.get(\"y\", None)\n",
    "        time = dataset.variables.get(\"time\", None)\n",
    "        dim_nb_series = [dim.name for dim in dataset.dimensions.values() if dim.name != 'time'][0]\n",
    "        if not all([x, y, time]):\n",
    "            raise CFDataRepositoryError(\"Something is wrong with the dataset.\"\n",
    "                                        \" x/y coords or time not found.\")\n",
    "        time = convert_netcdf_time(time.units + ' ' + '00:00', time)\n",
    "        data_cs = dataset.variables.get(\"crs\", None)\n",
    "        if data_cs is None:\n",
    "            raise CFDataRepositoryError(\"No coordinate system information in dataset.\")\n",
    "\n",
    "        time_slice, issubset = _make_time_slice(time, utc_period, CFDataRepositoryError)\n",
    "\n",
    "        x, y, m_xy, xy_slice = _limit_1D(x[:], y[:], data_cs.proj4, self.shyft_cs, geo_location_criteria, self._padding, CFDataRepositoryError)\n",
    "\n",
    "        raw_data = {}\n",
    "        for k in dataset.variables.keys():\n",
    "            if self._nc_shyft_map.get(k, None) in input_source_types:\n",
    "                if k in self._shift_fields and issubset:  # Add one to time slice\n",
    "                    data_time_slice = slice(time_slice.start, time_slice.stop + 1)\n",
    "                else:\n",
    "                    data_time_slice = time_slice\n",
    "                data = dataset.variables[k]\n",
    "                pure_arr = _slice_var_1D(data, dim_nb_series, xy_slice, m_xy, slices={'time': data_time_slice})\n",
    "                raw_data[self._nc_shyft_map[k]] = pure_arr, k\n",
    "\n",
    "        if \"z\" in dataset.variables.keys():\n",
    "            data = dataset.variables[\"z\"]\n",
    "            # dims = data.dimensions\n",
    "            # data_slice = len(data.dimensions)*[slice(None)]\n",
    "            # data_slice[dims.index(\"dim_nb_series\")] = m_xy\n",
    "            # z = data[data_slice]\n",
    "            z = data[m_xy]\n",
    "        else:\n",
    "            raise CFDataRepositoryError(\"No elevations found in dataset\")\n",
    "\n",
    "        # Make sure requested fields are valid, and that dataset contains the requested data.\n",
    "        if not self.allow_subset and not (set(raw_data.keys()).issuperset(input_source_types)):\n",
    "            raise CFDataRepositoryError(\"Could not find all data fields\")\n",
    "\n",
    "        extracted_data = self._transform_raw(raw_data, time[time_slice], issubset=issubset)\n",
    "        return _numpy_to_geo_ts_vec(extracted_data, x, y, z, CFDataRepositoryError)\n",
    "\n",
    "    def _transform_raw(self, data, time, issubset=False):\n",
    "        \"\"\"\n",
    "        We need full time if deaccumulating\n",
    "        \"\"\"\n",
    "\n",
    "        def noop_time(t):\n",
    "            return TimeAxis(UtcTimeVector.from_numpy(t.astype(int)), int(2*t[-1] - t[-2]))\n",
    "\n",
    "        def dacc_time(t):\n",
    "            return noop_time(t) if issubset else TimeAxis(UtcTimeVector.from_numpy(t.astype(int)))\n",
    "\n",
    "        def noop_space(x):\n",
    "            return x\n",
    "\n",
    "        def air_temp_conv(T):\n",
    "            return T - 273.15\n",
    "\n",
    "        def prec_conv(p):\n",
    "            return p[1:]\n",
    "\n",
    "        def prec_acc_conv(p):\n",
    "            return np.clip(p[1:] - p[:-1], 0.0, 1000.0)\n",
    "\n",
    "        def rad_conv(r):\n",
    "            dr = r[1:] - r[:-1]\n",
    "            return np.clip(dr/(time[1] - time[0]), 0.0, 5000.0)\n",
    "\n",
    "        # Unit- and aggregation-dependent conversions go here\n",
    "        convert_map = {\"wind_speed\": lambda x, t: (noop_space(x), noop_time(t)),\n",
    "                       \"relative_humidity\": lambda x, t: (noop_space(x), noop_time(t)),\n",
    "                       \"temperature\": lambda x, t: (noop_space(x), noop_time(t)),\n",
    "                       \"global_radiation\": lambda x, t: (noop_space(x), noop_time(t)),\n",
    "                       \"precipitation\": lambda x, t: (noop_space(x), noop_time(t)),\n",
    "                       \"precipitation_amount_acc\": lambda x, t: (prec_acc_conv(x), dacc_time(t)),\n",
    "                       \"discharge\": lambda x, t: (noop_space(x), noop_time(t))}\n",
    "        res = {}\n",
    "        for k, (v, ak) in data.items():\n",
    "            res[k] = convert_map[ak](v, time)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a065b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CFDataRepost in module __main__:\n",
      "\n",
      "class CFDataRepost(shyft.hydrology.repository.interfaces.GeoTsRepository)\n",
      " |  CFDataRepost(epsg, filename, padding=5000.0)\n",
      " |  \n",
      " |  Repository for geo located timeseries stored in netCDF files.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CFDataRepost\n",
      " |      shyft.hydrology.repository.interfaces.GeoTsRepository\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, epsg, filename, padding=5000.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_timeseries(self, input_source_types, utc_period, geo_location_criteria=None)\n",
      " |      see interfaces.GeoTsRepository\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from shyft.hydrology.repository.interfaces.GeoTsRepository:\n",
      " |  \n",
      " |  get_forecast(self, input_source_types: List[str], utc_period: Any, t_c: int, geo_location_criteria: Optional[Any] = None) -> Dict[str, Any]\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_source_types: list\n",
      " |          List of source types to retrieve (precipitation, temperature, ...)\n",
      " |      utc_period: UtcPeriod\n",
      " |          The utc time period that should (as a minimum) be covered.\n",
      " |      t_c: int\n",
      " |          Forecast specification; return newest forecast older than t_c.\n",
      " |      geo_location_criteria: {shapely.geometry.Polygon, shapely.geometry.MultiPolygon}\n",
      " |          Polygon defining the boundary for selecting points. All points located inside this boundary will be fetched.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      geo_loc_ts: dictionary\n",
      " |          dictionary keyed by source type, where values are api vectors of geo\n",
      " |          located timeseries.\n",
      " |          Important notice: The returned forecast time-series should at least cover the\n",
      " |          requested period. It could return *more* data than in\n",
      " |          the requested period, but must return sufficient data so\n",
      " |          that the f(t) can be evaluated over the requested period.\n",
      " |  \n",
      " |  get_forecast_collection(self, input_source_types: List, fc_selection_criteria: shyft.hydrology.repository.interfaces.ForecastSelectionCriteria, geo_location_criteria: Optional[Any] = None) -> List[Dict[str, Any]]\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_source_types: list\n",
      " |          List of source types to retrieve (precipitation, temperature, ...)\n",
      " |      fc_selection_criteria: ForecastSelectionCriteria\n",
      " |          Forecasts specifications; return all forecast that meet specification\n",
      " |      geo_location_criteria: {shapely.geometry.Polygon, shapely.geometry.MultiPolygon}\n",
      " |          Polygon defining the boundary for selecting points. All points located inside this boundary will be fetched.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      List of geo_loc_ts:\n",
      " |          List of dictionaries keyed by source type, where values are\n",
      " |          api vectors of geo located timeseries.\n",
      " |  \n",
      " |  get_forecast_ensemble(self, input_source_types: List[str], utc_period: Any, t_c: int, geo_location_criteria: Optional[Any] = None) -> List[Dict[str, Any]]\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_source_types: list\n",
      " |          List of source types to retrieve (precipitation, temperature, ...)\n",
      " |      utc_period: UtcPeriod\n",
      " |          The utc time period that should (as a minimum) be covered.\n",
      " |      t_c: int\n",
      " |          Forecast specification; return newest forecast older than t_c.\n",
      " |      geo_location_criteria: {shapely.geometry.Polygon, shapely.geometry.MultiPolygon}\n",
      " |          Polygon defining the boundary for selecting points. All points located inside this boundary will be fetched.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ensemble: list of same type as get_forecast\n",
      " |          Important notice: The returned forecast time-series should at least cover the\n",
      " |          requested period. It could return *more* data than in\n",
      " |          the requested period, but must return sufficient data so\n",
      " |          that the f(t) can be evaluated over the requested period.\n",
      " |  \n",
      " |  get_forecast_ensemble_collection(self, input_source_types: List, fc_selection_criteria: shyft.hydrology.repository.interfaces.ForecastSelectionCriteria, geo_location_criteria: Optional[Any] = None) -> List[List[Dict[str, Any]]]\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_source_types: list\n",
      " |          List of source types to retrieve (precipitation, temperature, ...)\n",
      " |      fc_selection_criteria: ForecastSelectionCriteria\n",
      " |          Forecasts specification; return all forecast that meet specification\n",
      " |      geo_location_criteria: {shapely.geometry.Polygon, shapely.geometry.MultiPolygon}\n",
      " |          Polygon defining the boundary for selecting points. All points located inside this boundary will be fetched.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      List (collection) of lists (ensemble members) of geo_loc_ts:\n",
      " |          List (collection indexed) of lists (ensemble indexed) dictionaries\n",
      " |          keyed by source type, where values are api vectors of geo located\n",
      " |          timeseries.\n",
      " |  \n",
      " |  get_timeseries_ensemble(self, input_source_types: List[str], utc_period: Any, geo_location_criteria: Optional[Any] = None) -> List[Dict[str, Any]]\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_source_types: list\n",
      " |          List of source types to retrieve (precipitation,temperature..)\n",
      " |      utc_period: UtcPeriod\n",
      " |          The utc time period that should (as a minimum) be covered.\n",
      " |      geo_location_criteria: {shapely.geometry.Polygon, shapely.geometry.MultiPolygon}\n",
      " |          Polygon defining the boundary for selecting points. All points located inside this boundary will be fetched.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ensemble: list of same type as get_timeseries\n",
      " |          Important notice: The returned time-series should at least cover the\n",
      " |          requested period. It could return *more* data than in\n",
      " |          the requested period, but must return sufficient data so\n",
      " |          that the f(t) can be evaluated over the requested period.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from shyft.hydrology.repository.interfaces.GeoTsRepository:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from shyft.hydrology.repository.interfaces.GeoTsRepository:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CFDataRepost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c41c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
